{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline \n",
    "In this notebook we will create two new tables in a `postgreSQL` database, `arxiv_detex` and `arxiv_pandoc`. These tables will contain the titles and abstracts of the articles from `arXiv` after having been processed by `detex` and `pandoc`. Sometimes these processing steps fail, and when they do we just store the original string in the new tables. Both of these new tables have the following columns.\n",
    "\n",
    "\n",
    "| id | created | setspec | title | title_converted | abstract | abstract_converted |\n",
    "|----|---------|---------|-------|-----------------|----------|--------------------|\n",
    "| | | | |  | | | |\n",
    "\n",
    "Where the `title_converted` and `abstract_converted` features are boolean, and are `f` only when the appropriate program used to convert the text failed to return anything and `t` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up $\\LaTeX$\n",
    "\n",
    "There's a bit of a mismatch between the tools we're using and the task at hand. The abstracts and titles are written in $\\LaTeX$. This creates a few different problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "My favorite theorem is Euler's equation. Euler's equation says\n",
    "$$\n",
    "e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta).\n",
    "$$\n",
    "Euler's equation can be proven using the power series representations of the three functions $e^{i\\theta}, \\cos(\\theta)$ and $\\sin(\\theta)$. For example \n",
    "\n",
    "$$\n",
    "\\sum_{n=0}^\\infty \\frac{x^n}{n!} = e^x\n",
    "$$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This text block, after being run through a $\\LaTeX$ compiler would produce a document (e.g. a PDF) that looks something like the cell below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My favorite theorem is Euler's equation. Euler's equation says\n",
    "$$\n",
    "e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta).\n",
    "$$\n",
    "Euler's equation can be proven using the power series representations of the three functions $e^{i\\theta}, \\cos(\\theta)$ and $\\sin(\\theta)$. For example \n",
    "\n",
    "$$\n",
    "\\sum_{n=0}^\\infty \\frac{x^n}{n!} = e^x.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that the NLP tools aren't set up to handle all of the peculiarities of $\\LaTeX$. To get around this, I used a program called `detex`, that takes the raw $\\LaTeX$ above and converts it to the text below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My favorite theorem is Euler's equation. Euler's equation says\n",
      "\n",
      "\n",
      "\n",
      "Euler's equation can be proven using the power series representations of the three functions  and . For example \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "str_to_fix = r\"\"\"\n",
    "My favorite theorem is Euler's equation. Euler's equation says\n",
    "$$\n",
    "e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta).\n",
    "$$\n",
    "Euler's equation can be proven using the power series representations of the three functions $e^{i\\theta}, \\cos(\\theta)$ and $\\sin(\\theta)$. For example \n",
    "\n",
    "$$\n",
    "\\sum_{n=0}^\\infty \\frac{x^n}{n!} = e^x\n",
    "$$\n",
    "\"\"\"\n",
    "\n",
    "str_to_fix = bytes(str_to_fix, encoding='utf-8')\n",
    "detex_path = '/usr/bin/detex'\n",
    "\n",
    "new_str = subprocess.run(detex_path.split(), input=str_to_fix, stdout=subprocess.PIPE) \n",
    "new_str = new_str.stdout\n",
    "new_str = str(new_str, encoding='utf-8')\n",
    "print(new_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we've lost information here, but the goal of converting our $\\LaTeX$ to plain text was never about preserving all information, but preserving the information we are able to in a format with which we can work. The plain text abov is certainly something that `spaCy` could understand and work with. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WARNING\n",
    "\n",
    "Not everything in the metadata is proper $\\LaTeX$. `detex` won't catch bad code, it will just try to convert it without really parsing the code. For example, let's try the following variation on the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```text\n",
    "My favorite theorem is Euler's equation. Euler's equation says\n",
    "$$\n",
    "e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta).\n",
    "$$\n",
    "Euler's equation can be proven using the power series representations of the three functions $e^{i\\theta}, \\cos(\\theta)$ and $\\sin(\\theta)$. For example \n",
    "\n",
    "$\n",
    "\\sum_{n=0}^\\infty \\frac{x^n}{n!} = e^x\n",
    "$$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we've changed here is to remove the `$` in the second equation. This is a critical $\\LaTeX$ error, the above code will fail to generate correct document. However, `detex` will not figure this out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My favorite theorem is Euler's equation. Euler's equation says\n",
      "\n",
      "e^i = () + i().\n",
      "Euler's equation can be proven using the power series representations of the three functions  and . For example \n",
      "\n",
      "\n",
      "_n=0^x^nn! = e^x\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str_to_fix = r\"\"\"\n",
    "My favorite theorem is Euler's equation. Euler's equation says\n",
    "\n",
    "e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta).\n",
    "Euler's equation can be proven using the power series representations of the three functions $e^{i\\theta}, \\cos(\\theta)$ and $\\sin(\\theta)$. For example \n",
    "\n",
    "\n",
    "\\sum_{n=0}^\\infty \\frac{x^n}{n!} = e^x\n",
    "$$\n",
    "\"\"\"\n",
    "\n",
    "str_to_fix = bytes(str_to_fix, encoding='utf-8')\n",
    "\n",
    "new_str = subprocess.run(detex_path.split(), input=str_to_fix, stdout=subprocess.PIPE) \n",
    "new_str = new_str.stdout\n",
    "new_str = str(new_str, encoding='utf-8')\n",
    "print(new_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another program, `pandoc`, can be used to try to convert individual $\\LaTeX$ documents to plain text (`pandoc` is a general document converted, not $\\LaTeX$ specific). For the above broken example, `pandoc` would fail to convert the text and give an error. Unlike `detex`, there is a convenient Python `pandoc` wrapper that we can use, rather than converting to byte strings and feed it to the external program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandoc failed to parse the string\n"
     ]
    }
   ],
   "source": [
    "import pypandoc\n",
    "\n",
    "try:\n",
    "    x = pypandoc.convert_text(new_str, to='plain', format='tex')\n",
    "    print('pandoc parsed the string successfully')\n",
    "except:\n",
    "    print('pandoc failed to parse the string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some errors are not caught by `pandoc`. The string \n",
    "\n",
    "```text\n",
    "My favorite theorem is Euler's equation. Euler's equation says\n",
    "\n",
    "e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta).\n",
    "$$\n",
    "```\n",
    "shouldn't be accepted by a $\\LaTeX$ compiler, but `pandoc` won't catch the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandoc parsed the string successfully\n"
     ]
    }
   ],
   "source": [
    "str_to_fix = r\"\"\"\n",
    "My favorite theorem is Euler's equation. Euler's equation says\n",
    "\n",
    "e^{i\\theta} = \\cos(\\theta) + i\\sin(\\theta).\n",
    "$$\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    x = pypandoc.convert_text(str_to_fix, to='plain', format='latex')\n",
    "    print('pandoc parsed the string successfully')\n",
    "except:\n",
    "    print('pandoc failed to parse the string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite theorem is Euler’s equation. Euler’s equation says\n",
      "\n",
      "e^i = () + i().\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all these caveats in mind, I am going to treat those abstracts which `pandoc` returns a value for as \"valid\" and later on when we train our GloVe vectors, we will train only on those abstracts. In the next notebook we'll take a look at the actual rates at which `pandoc` fails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "We use `sqlalchemy` as our framework for interacting with the `postgres` server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Column, String, Integer, DATE, BOOLEAN\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import func\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the required credentials to access the databse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../postgres.json') as pg_info:\n",
    "    pg_json = json.load(pg_info)\n",
    "    pg_username = pg_json['pg_username']\n",
    "    pg_password = pg_json['pg_password']\n",
    "    pg_ip = pg_json['pg_ip']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the objects that `sqlalchemy` uses to represent the tables in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class articles_raw(Base):\n",
    "    __tablename__ = 'arxiv_raw'\n",
    "    \n",
    "    id = Column(String, primary_key=True)\n",
    "    created = Column(DATE)\n",
    "    setspec = Column(String)\n",
    "    title = Column(String)\n",
    "    abstract = Column(String)\n",
    "    \n",
    "class articles_detex(Base):\n",
    "    __tablename__ = 'arxiv_detex'\n",
    "    \n",
    "    id = Column(String, primary_key=True)\n",
    "    created = Column(DATE)\n",
    "    setspec = Column(String)\n",
    "    \n",
    "    title = Column(String)\n",
    "    title_converted = Column(BOOLEAN)\n",
    "    \n",
    "    abstract = Column(String)\n",
    "    abstract_converted = Column(BOOLEAN)\n",
    "    \n",
    "engine = create_engine(f'postgres://{pg_username}:{pg_password}@{pg_ip}:5432')\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "\n",
    "class articles_pandoc(Base):\n",
    "    __tablename__ = 'arxiv_pandoc'\n",
    "    \n",
    "    id = Column(String, primary_key=True)\n",
    "    created = Column(DATE)\n",
    "    setspec = Column(String)\n",
    "    \n",
    "    title = Column(String)\n",
    "    title_converted = Column(BOOLEAN)\n",
    "    \n",
    "    abstract = Column(String)\n",
    "    abstract_converted = Column(BOOLEAN)\n",
    "    \n",
    "engine = create_engine(f'postgres://{pg_username}:{pg_password}@{pg_ip}:5432')\n",
    "Base.metadata.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `str_fix` function either runs `detex` or `pandoc` on the string, depending on what we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_fix(str_to_fix, detex_path, use_pandoc=None):\n",
    "    if not use_pandoc:\n",
    "        str_to_fix = bytes(str_to_fix, 'utf-8')\n",
    "        try:\n",
    "            new_str = subprocess.run(detex_path.split(), input=str_to_fix, stdout=subprocess.PIPE) \n",
    "            new_str = new_str.stdout\n",
    "            detexed = True\n",
    "        except:\n",
    "            new_str = str_to_fix\n",
    "            detexed = False\n",
    "\n",
    "        new_str = str(new_str, 'utf-8')\n",
    "        return new_str, detexed\n",
    "    else:\n",
    "        try:\n",
    "            new_str = pypandoc.convert_text(str_to_fix, to='plain', format='latex')\n",
    "            panddoc_bool = True\n",
    "        except:\n",
    "            new_str = str_to_fix\n",
    "            panddoc_bool = False\n",
    "            \n",
    "        return new_str, panddoc_bool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `change_tex` function fixes up a record from `arxiv_raw` and processes it for insertion into one of `arxiv_detex` or `arxiv_pandoc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_tex(record, detex_path, use_pandoc, article_class):\n",
    "    processed_article_info = {\n",
    "                'id':record.id,\n",
    "                'created':record.created,\n",
    "                'setspec':record.setspec,\n",
    "                'title':record.title,\n",
    "                'abstract':record.abstract,\n",
    "            }\n",
    "    \n",
    "    \n",
    "    processed_abstract, abstract_bool = str_fix(record.abstract, detex_path, use_pandoc)\n",
    "    processed_title, title_bool = str_fix(record.title, detex_path, use_pandoc)\n",
    "    \n",
    "    processed_article_info['abstract'] = processed_abstract\n",
    "    processed_article_info['abstract_converted'] = abstract_bool\n",
    "    \n",
    "    processed_article_info['title'] = processed_title\n",
    "    processed_article_info['title_converted'] = title_bool\n",
    "    \n",
    "\n",
    "    processed_article = article_class(**processed_article_info)\n",
    "    return processed_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `query_tex` function processes the rows of `arxiv_raw` and inserts the processed rose into either `arxiv_detex` or `arxiv_pandoc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_tex(limit_num=None, detex_path='/usr/bin/detex', batch_size=10000,\n",
    "              commit_size=1000, use_pandoc=None, article_class=articles_detex):\n",
    "    \n",
    "    engine = create_engine(f'postgres://{pg_username}:{pg_password}@{pg_ip}:5432')\n",
    "    Session = sessionmaker(engine)\n",
    "\n",
    "    query_session = Session()\n",
    "    commit_session = Session()\n",
    "    \n",
    "    if limit_num:\n",
    "        query = query_session.query(articles_raw).limit(limit_num)\n",
    "\n",
    "    else:\n",
    "        query = query_session.query(articles_raw).yield_per(batch_size)\n",
    "    \n",
    "    new_records = []\n",
    "    \n",
    "    for row_num, record in enumerate(query): \n",
    "        processed_article = change_tex(record, detex_path=detex_path,\n",
    "                                       use_pandoc=use_pandoc, article_class=article_class)\n",
    "        new_records.append(processed_article)\n",
    "        \n",
    "        if row_num % commit_size == 0:\n",
    "            commit_session.add_all(new_records)\n",
    "            commit_session.commit()\n",
    "            new_records = []\n",
    "    \n",
    "    commit_session.add_all(new_records)    \n",
    "    commit_session.commit()\n",
    "    \n",
    "    commit_session.close()\n",
    "    query_session.close()\n",
    "    engine.dispose()\n",
    "        \n",
    "    \n",
    "    return row_num\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the `arxiv_detex` table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_nums = query_tex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the `arxiv_pandoc` table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_nums = query_tex(use_pandoc=True, article_class=articles_pandoc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
