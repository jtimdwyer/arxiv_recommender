{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a SQLAlchemy `sessionmaker`\n",
    "The `sqlalchemy_load.py` is setup to load a session maker which is already pointed at the `postgres` server. We'll use the `sessionmaker` object to manage transactions with database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy_arxiv import Session, articles_raw, articles_vectors\n",
    "from sqlalchemy import func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the query and tokenizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "query = session.query(articles_raw).limit(100)\n",
    "df = pd.read_sql(query.statement, query.session.bind)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>setspec</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1506.00545</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>physics:cond-mat</td>\n",
       "      <td>Area law and its violation: A microscopic insp...</td>\n",
       "      <td>Quantum fluctuations of local quantities can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1506.00546</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>physics:hep-ex</td>\n",
       "      <td>An amplitude analysis of the $\\pi^{0}\\pi^{0}$ ...</td>\n",
       "      <td>An amplitude analysis of the $\\pi^{0}\\pi^{0}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1506.00547</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>cs</td>\n",
       "      <td>Differential Geometric SLAM</td>\n",
       "      <td>The simultaneous localization and mapping (S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1506.00548</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>cs</td>\n",
       "      <td>GRADOOP: Scalable Graph Data Management and An...</td>\n",
       "      <td>Many Big Data applications in business and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1506.00549</td>\n",
       "      <td>2015-06-01</td>\n",
       "      <td>physics:cond-mat</td>\n",
       "      <td>Quantum Monte Carlo study of strange correlato...</td>\n",
       "      <td>Distinguishing the nontrivial symmetry-prote...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id     created           setspec  \\\n",
       "0  1506.00545  2015-06-01  physics:cond-mat   \n",
       "1  1506.00546  2015-06-01    physics:hep-ex   \n",
       "2  1506.00547  2015-06-01                cs   \n",
       "3  1506.00548  2015-06-01                cs   \n",
       "4  1506.00549  2015-06-01  physics:cond-mat   \n",
       "\n",
       "                                               title  \\\n",
       "0  Area law and its violation: A microscopic insp...   \n",
       "1  An amplitude analysis of the $\\pi^{0}\\pi^{0}$ ...   \n",
       "2                        Differential Geometric SLAM   \n",
       "3  GRADOOP: Scalable Graph Data Management and An...   \n",
       "4  Quantum Monte Carlo study of strange correlato...   \n",
       "\n",
       "                                            abstract  \n",
       "0    Quantum fluctuations of local quantities can...  \n",
       "1    An amplitude analysis of the $\\pi^{0}\\pi^{0}...  \n",
       "2    The simultaneous localization and mapping (S...  \n",
       "3    Many Big Data applications in business and s...  \n",
       "4    Distinguishing the nontrivial symmetry-prote...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's my plan here\n",
    "\n",
    "1. loop over the table so I can process each abstract\n",
    "2. format the latex as best as I can \n",
    "\n",
    "    i. This should be a stripped string, so not ending or starting with whitespace\n",
    "    \n",
    "    ii. The only white space allowed will be spaces, no tabs, newlines etc.\n",
    "    \n",
    "    iii. Latex commands should be grouped together, make `\\begin{align}` a token etc.\n",
    "    \n",
    "3. write the formatted version to a file, separate documents by newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex_repl(latex_string):\n",
    "    return \" \" + latex_string.group(0) + \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latex():\n",
    "    #things to add spaces between\n",
    "    dollar_sign = r'\\${1,2}'\n",
    "    \n",
    "    parens = r\"\\\\\\(|\\\\\\)\"\n",
    "    \n",
    "    brackets_left = r\"\\\\[\"\n",
    "    brackets_right = r\"\\\\]\"\n",
    "    \n",
    "    #things like \\begins, \\mathbb, \\emph etc\n",
    "    commands = r'\\\\[a-zA-Z]+?\\{.*?\\}'\n",
    "    \n",
    "    \n",
    "    \n",
    "    constants_functions = r'\\\\[a-zA-Z]+'\n",
    "    simple_math = '[+=\\-/]'\n",
    "\n",
    "    pattern = [\n",
    "        dollar_sign,\n",
    "        brackets_right,\n",
    "        brackets_right,\n",
    "        parens,\n",
    "        commands,\n",
    "        constants_functions,\n",
    "        simple_math,\n",
    "    ]\n",
    "    \n",
    "    pattern = \"|\".join(pattern)\n",
    "\n",
    "    regex_compiled = re.compile(pattern, flags=re.DOTALL)\n",
    "    \n",
    "    return regex_compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_abstract(abstract, latex_regex, latex_repl, whitespace_regex):\n",
    "    abstract = latex_regex.sub(latex_repl, abstract)\n",
    "    abstract = whitespace_regex.sub(' ', abstract)\n",
    "    stop_words_removed = [ word for word in abstract.strip().split() if word.lower() not in ENGLISH_STOP_WORDS ]\n",
    "    return ' '.join(stop_words_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  We present a new extensive analysis of the old problem of finding a\\nsatisfactory calibration of the relation between the geometric albedo and some\\nmeasurable polarization properties of the asteroids. To achieve our goals, we\\nuse all polarimetric data at our disposal. For the purposes of calibration, we\\nuse a limited sample of objects for which we can be confident to know the\\nalbedo with good accuracy, according to previous investigations of other\\nauthors. We find a new set of updated calibration coefficients for the\\nclassical slope - albedo relation, but we generalize our analysis and we\\nconsider also alternative possibilities, including the use of other\\npolarimetric parameters, one being proposed here for the first time, and the\\npossibility to exclude from best-fit analyzes the asteroids having low albedos.\\nWe also consider a possible parabolic fit of the whole set of data.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = df.at[10,'abstract']\n",
    "abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'present new extensive analysis old problem finding satisfactory calibration relation geometric albedo measurable polarization properties asteroids achieve goals use polarimetric data disposal purposes calibration use limited sample objects confident know albedo good accuracy according previous investigations authors new set updated calibration coefficients classical slope - albedo relation generalize analysis consider alternative possibilities including use polarimetric parameters proposed time possibility exclude best - fit analyzes asteroids having low albedos consider possible parabolic fit set data'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = df.at[10,'abstract']\n",
    "\n",
    "latex_regex = latex()\n",
    "whitespace_regex = re.compile('[:;.,?\\s]+')\n",
    "\n",
    "process_abstract(abstract, latex_regex, latex_repl, whitespace_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a corpus text file.\n",
    "\n",
    "Some of the processes below are a bit intensive. I ran this notebook in a `t2.large` instance on AWS. The `wall time` output below refers to actual time (measured by the computer), i.e. the time according to \"The clock on the wall\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_processor(session, table_class, corpus_file_path,\n",
    "                    batch_size, latex_regex, latex_repl, whitespace_regex):\n",
    "    \n",
    "    query = session.query(table_class.abstract).yield_per(batch_size)\n",
    "    \n",
    "    with open(corpus_file_path, 'w') as corpus:\n",
    "        for row in query:\n",
    "            abstract = row.abstract\n",
    "            abstract = process_abstract(abstract, latex_regex, latex_repl, whitespace_regex)\n",
    "            corpus.write(abstract + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = {\n",
    "#     'session':Session(),\n",
    "#     'table_class':articles_raw,\n",
    "#     'corpus_file_path':'../../vectors/arxiv_corpus.txt',\n",
    "#     'batch_size':1000,\n",
    "#     'latex_regex':latex_regex,\n",
    "#     'latex_repl':latex_repl,\n",
    "#     'whitespace_regex':whitespace_regex,\n",
    "# }\n",
    "\n",
    "# %time table_processor(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def train_GloVe():\n",
    "    cmd = [\"./glove_arxiv.sh\"]\n",
    "    with open(\"glove.log\", \"w\") as log:\n",
    "        subprocess.run(cmd, stderr=log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below took about 24 hours on a `t2.2xlarge` instance from AWS EC2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_GloVe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors for abstracts\n",
    "\n",
    "Reading the output of the `GloVe` vectors into a `pandas` DataFrame presented some odd challenges. Even set up correctly, specifying the proper separator etc., for some reason a small fraction of the rows were not read correctly, some index elements were doubled and some entire rows were read as indexes. To address this issue, I first tried to use the `np.genfromtext` method to read the file directly as an array. This also failed.\n",
    "\n",
    "Ultimately I just read the file in manually and explicitly constructed a DataFrame.\n",
    "\n",
    "I discovered this issue by looking at the lengths of different elements in the DataFrame index and saw a number of index elements (the `GloVe` tokens) that were more than one-hundred thousand characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../vectors/GloVe_scratch_files/vectors.txt', 'r') as file:\n",
    "    lines = file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_split(line, cols, index):\n",
    "    label, *vector = line.split()\n",
    "    index.append(label)\n",
    "    \n",
    "    for col_num, new_value in enumerate(vector):\n",
    "        cols[col_num].append(new_value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = {i:[] for i in range(300)}\n",
    "index = []\n",
    "\n",
    "for line in lines:\n",
    "    row_split(line, cols, index)\n",
    "\n",
    "df = pd.DataFrame(data=cols, index=index).astype(float)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>0.221337</td>\n",
       "      <td>0.034171</td>\n",
       "      <td>-0.118100</td>\n",
       "      <td>-0.172244</td>\n",
       "      <td>-0.117517</td>\n",
       "      <td>0.128754</td>\n",
       "      <td>-0.116952</td>\n",
       "      <td>-0.028031</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.010180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.199566</td>\n",
       "      <td>0.091558</td>\n",
       "      <td>-0.025151</td>\n",
       "      <td>-0.073502</td>\n",
       "      <td>-0.143817</td>\n",
       "      <td>-0.247823</td>\n",
       "      <td>0.089644</td>\n",
       "      <td>-0.154207</td>\n",
       "      <td>0.135924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>0.570122</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>-0.226462</td>\n",
       "      <td>0.163964</td>\n",
       "      <td>-0.141922</td>\n",
       "      <td>0.023358</td>\n",
       "      <td>-0.216404</td>\n",
       "      <td>-0.382666</td>\n",
       "      <td>-0.047065</td>\n",
       "      <td>0.433195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074485</td>\n",
       "      <td>0.425720</td>\n",
       "      <td>-0.032990</td>\n",
       "      <td>0.137178</td>\n",
       "      <td>-0.172863</td>\n",
       "      <td>0.279619</td>\n",
       "      <td>0.578546</td>\n",
       "      <td>-0.149470</td>\n",
       "      <td>0.093483</td>\n",
       "      <td>-0.060006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.230135</td>\n",
       "      <td>0.122644</td>\n",
       "      <td>0.185519</td>\n",
       "      <td>-0.034758</td>\n",
       "      <td>-0.236756</td>\n",
       "      <td>0.117980</td>\n",
       "      <td>-0.215023</td>\n",
       "      <td>-0.135311</td>\n",
       "      <td>0.253569</td>\n",
       "      <td>0.096707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>0.079115</td>\n",
       "      <td>-0.155606</td>\n",
       "      <td>-0.144959</td>\n",
       "      <td>0.156771</td>\n",
       "      <td>-0.164449</td>\n",
       "      <td>-0.417972</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>-0.024429</td>\n",
       "      <td>0.098938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/</th>\n",
       "      <td>0.045956</td>\n",
       "      <td>0.271367</td>\n",
       "      <td>-0.392238</td>\n",
       "      <td>-0.259288</td>\n",
       "      <td>-0.272326</td>\n",
       "      <td>-0.161802</td>\n",
       "      <td>0.072062</td>\n",
       "      <td>-0.191248</td>\n",
       "      <td>-0.225739</td>\n",
       "      <td>-0.172222</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005772</td>\n",
       "      <td>0.013629</td>\n",
       "      <td>0.012839</td>\n",
       "      <td>-0.014166</td>\n",
       "      <td>0.076333</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.160343</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>-0.216186</td>\n",
       "      <td>0.002026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>=</th>\n",
       "      <td>0.084244</td>\n",
       "      <td>0.014944</td>\n",
       "      <td>-0.228621</td>\n",
       "      <td>0.041487</td>\n",
       "      <td>-0.076570</td>\n",
       "      <td>-0.190362</td>\n",
       "      <td>-0.490148</td>\n",
       "      <td>-0.123931</td>\n",
       "      <td>0.126358</td>\n",
       "      <td>0.247899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042797</td>\n",
       "      <td>0.206089</td>\n",
       "      <td>-0.154815</td>\n",
       "      <td>0.264402</td>\n",
       "      <td>-0.213689</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.192470</td>\n",
       "      <td>-0.124478</td>\n",
       "      <td>-0.008774</td>\n",
       "      <td>-0.069953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "-      0.221337  0.034171 -0.118100 -0.172244 -0.117517  0.128754 -0.116952   \n",
       "$      0.570122  0.025272 -0.226462  0.163964 -0.141922  0.023358 -0.216404   \n",
       "model  0.230135  0.122644  0.185519 -0.034758 -0.236756  0.117980 -0.215023   \n",
       "/      0.045956  0.271367 -0.392238 -0.259288 -0.272326 -0.161802  0.072062   \n",
       "=      0.084244  0.014944 -0.228621  0.041487 -0.076570 -0.190362 -0.490148   \n",
       "\n",
       "            7         8         9      ...          290       291       292  \\\n",
       "-     -0.028031  0.048693  0.010180    ...     0.075310  0.199566  0.091558   \n",
       "$     -0.382666 -0.047065  0.433195    ...     0.074485  0.425720 -0.032990   \n",
       "model -0.135311  0.253569  0.096707    ...     0.036827  0.079115 -0.155606   \n",
       "/     -0.191248 -0.225739 -0.172222    ...     0.005772  0.013629  0.012839   \n",
       "=     -0.123931  0.126358  0.247899    ...    -0.042797  0.206089 -0.154815   \n",
       "\n",
       "            293       294       295       296       297       298       299  \n",
       "-     -0.025151 -0.073502 -0.143817 -0.247823  0.089644 -0.154207  0.135924  \n",
       "$      0.137178 -0.172863  0.279619  0.578546 -0.149470  0.093483 -0.060006  \n",
       "model -0.144959  0.156771 -0.164449 -0.417972  0.015737 -0.024429  0.098938  \n",
       "/     -0.014166  0.076333  0.026164  0.160343  0.112870 -0.216186  0.002026  \n",
       "=      0.264402 -0.213689  0.084507  0.192470 -0.124478 -0.008774 -0.069953  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_doc_vector(document, word_df):\n",
    "    document = document.split()\n",
    "    \n",
    "    vector = np.array([0.0 for _ in word_df.columns])\n",
    "    \n",
    "    for token in document:\n",
    "        if token in word_df.index:\n",
    "            vector += word_df.loc[token,:].values\n",
    "    return vector\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_csv(article_class,\n",
    "                 session,\n",
    "                 latex_regex,\n",
    "                 latex_repl,\n",
    "                 whitespace_regex,\n",
    "                 process_abstract,\n",
    "                 word_df,\n",
    "                 output_file\n",
    "                ):\n",
    "    \n",
    "    query = session.query(article_class.id, article_class.abstract).yield_per(10000)\n",
    "    \n",
    "    with open(output_file, \"w\") as file:\n",
    "        for record in query:\n",
    "            abstract = process_abstract(record.abstract, latex_regex, latex_repl, whitespace_regex)\n",
    "            abstract_vector = build_doc_vector(abstract, word_df)\n",
    "            abstract_vector = list(abstract_vector)\n",
    "            abstract_vector = [str(vector_component) for vector_component in abstract_vector]\n",
    "\n",
    "            new_line = [record.id]\n",
    "            new_line.extend(abstract_vector)\n",
    "            new_line = ', '.join(new_line) + '\\n'\n",
    "            \n",
    "            file.write(new_line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below took about 6 hours to run on a `t2.large`. In the future I should look into parallelizing this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "output_file = \"../../vectors/arxiv_vectors.csv\"\n",
    "article_vectors = abstract_csv(articles_raw,\n",
    "                               session,\n",
    "                               latex_regex,\n",
    "                               latex_repl,\n",
    "                               whitespace_regex,\n",
    "                               process_abstract,\n",
    "                               word_df=df,\n",
    "                               output_file=output_file,\n",
    ")\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass it back to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_to_db(vector_file='../../vectors/arxiv_vectors.csv', session=None):\n",
    "    with open(vector_file, newline='', mode='r') as vector_csv:\n",
    "        csv_reader = csv.reader(vector_csv)\n",
    "        new_records = []\n",
    "        for line_num, line in enumerate(csv_reader):\n",
    "            \n",
    "            arxiv_id, *vector = line\n",
    "            vector = [float(comp) for comp in vector]\n",
    "            table_args = {f'comp_{i}':vector[i] for i in range(300) }\n",
    "            table_args['id'] = arxiv_id\n",
    "            new_table_entry = articles_vectors(**table_args)\n",
    "            new_records.append(new_table_entry)\n",
    "\n",
    "            #update every now and then.\n",
    "            if line_num % 1000 == 0:\n",
    "                session.add_all(new_records)\n",
    "                session.commit()\n",
    "            \n",
    "                new_records = []\n",
    "                \n",
    "        #final table update\n",
    "        session.add_all(new_records)\n",
    "        session.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "%time migrate_to_db(session=session)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
